{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "t = torch.cuda.get_device_properties(0).total_memory\n",
    "c = torch.cuda.memory_cached(0)\n",
    "a = torch.cuda.memory_allocated(0)\n",
    "f = c-a  # free inside cache\n",
    "\n",
    "#GiB, GiB, MiB\n",
    "print(c*9.31323e-10, a*9.31323e-10, f*9.53674e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "PRE_TRAINED_MODEL_NAME = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize input\n",
    "text = \"[CLS] Who was Jim Henson ? [SEP] Jim Henson was a puppeteer [SEP]\"\n",
    "tokenized_text = tokenizer.tokenize(text)\n",
    "\n",
    "# Mask a token that we will try to predict back with `BertForMaskedLM`\n",
    "masked_index = 8\n",
    "tokenized_text[masked_index] = '[MASK]'\n",
    "assert tokenized_text == ['[CLS]', 'who', 'was', 'jim', 'henson', '?', '[SEP]', 'jim', '[MASK]', 'was', 'a', 'puppet', '##eer', '[SEP]']\n",
    "\n",
    "# Convert token to vocabulary indices\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "# Define sentence A and B indices associated to 1st and 2nd sentences (see paper)\n",
    "segments_ids = [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\n",
    "\n",
    "# Convert inputs to PyTorch tensors\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "segments_tensors = torch.tensor([segments_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForMaskedLM(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyMLMHead(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=30522, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pre-trained model (weights)\n",
    "model = BertForMaskedLM.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have a GPU, put everything on cuda\n",
    "tokens_tensor = tokens_tensor.to('cuda')\n",
    "segments_tensors = segments_tensors.to('cuda')\n",
    "model.to('cuda')\n",
    "\n",
    "# Predict all tokens\n",
    "with torch.no_grad():\n",
    "    outputs = model(tokens_tensor, token_type_ids=segments_tensors)\n",
    "    predictions = outputs[0]\n",
    "\n",
    "# confirm we were able to predict 'henson'\n",
    "predicted_index = torch.argmax(predictions[0, masked_index]).item()\n",
    "predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])[0]\n",
    "assert predicted_token == 'henson'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_tensor[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30522])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0, masked_index].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\"The capital of France is Paris.\", return_tensors=\"pt\")\n",
    "\n",
    "word_predictions = model(inputs['input_ids'].to('cuda'))[0].squeeze() \n",
    "topk = torch.topk(word_predictions, 10, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inputs['input_ids'][0]) # input token length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 30522])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 10])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk.indices.shape # top k for each position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.5360,  3.7034,  3.5518,  3.2573,  3.1019,  3.0274,  2.7868,  2.6771,\n",
       "          2.6359,  2.5978],\n",
       "        [11.0378,  8.0880,  6.3868,  5.4343,  5.1208,  4.8960,  4.8887,  4.7132,\n",
       "          4.4590,  4.2406],\n",
       "        [17.6578,  9.6180,  8.0931,  7.6649,  7.3685,  6.8899,  6.7253,  6.3087,\n",
       "          6.2462,  5.8625],\n",
       "        [16.3969,  8.4188,  6.6246,  6.5789,  6.5786,  6.4317,  6.2958,  5.6894,\n",
       "          5.6806,  5.5124],\n",
       "        [13.2460,  7.7034,  6.7914,  6.6446,  5.5573,  5.2808,  5.1723,  4.9485,\n",
       "          4.8182,  4.4374],\n",
       "        [19.8579, 11.4044,  9.6445,  8.6700,  8.6540,  8.0095,  7.9143,  7.8865,\n",
       "          7.7478,  7.4902],\n",
       "        [15.2259,  8.5628,  7.3761,  6.5790,  6.5699,  6.4537,  6.0010,  5.8589,\n",
       "          5.6182,  5.5707],\n",
       "        [23.5132, 11.9360,  8.4535,  8.2309,  6.3016,  5.7213,  5.6281,  5.0736,\n",
       "          4.8223,  4.1219],\n",
       "        [13.3844,  6.7723,  6.5669,  5.9021,  4.7238,  4.4388,  4.2837,  4.2774,\n",
       "          4.0048,  3.7668]], device='cuda:0', grad_fn=<TopkBackward>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.1324, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ -6.4346,  -6.4063,  -6.4097,  ...,  -5.7691,  -5.6326,  -3.7883],\n",
       "         [-14.0120, -14.7241, -14.2120,  ..., -11.6977, -10.7304, -12.7618],\n",
       "         [ -9.6561, -10.3124,  -9.7458,  ...,  -8.7781,  -6.6036, -12.6595],\n",
       "         ...,\n",
       "         [ -3.7861,  -3.8572,  -3.5644,  ...,  -2.5592,  -3.1093,  -4.3819],\n",
       "         [-11.6598, -11.4274, -11.9267,  ...,  -9.8772, -10.2103,  -4.7594],\n",
       "         [-11.7267, -11.7509, -11.8040,  ..., -10.5943, -10.9407,  -7.5151]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "substitues (l, K), l is the length of subwords, K is the top-K predictions\n",
    "subsititues_score: (l, K) top-K prediction scores\n",
    "'''\n",
    "# for a single word w_j, top_k predictions candidates P^j\n",
    "# filter out stop words collected from NLTK\n",
    "# filter out antonyms using synonym dictionaries\n",
    "\n",
    "# construct a perturbed seuqence, break the loop if already predict indirectly\n",
    "# otherwise, select the best perturbation and turn to the next word in word list L\n",
    "def get_substitues(substitutes, tokenizer, mlm_model, use_bpe, substitutes_score=None, threshold=3.0):\n",
    "    # substitues L,k\n",
    "    # from this matrix to recover a word\n",
    "    words = []\n",
    "    sub_len, k = substitutes.size()  # sub-len, k\n",
    "\n",
    "    if sub_len == 0:\n",
    "        return words\n",
    "        \n",
    "    elif sub_len == 1: # whole phrase\n",
    "        for (i,j) in zip(substitutes[0], substitutes_score[0]):\n",
    "            if threshold != 0 and j < threshold: # score has to be above a threshold\n",
    "                break\n",
    "            words.append(tokenizer._convert_id_to_token(int(i)))\n",
    "    else:\n",
    "        if use_bpe == 1:\n",
    "            words = get_bpe_substitues(substitutes, tokenizer, mlm_model)\n",
    "        else:\n",
    "            return words\n",
    "    #\n",
    "    # print(words)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bpe_substitues(substitutes, tokenizer, mlm_model):\n",
    "    # substitutes L, k\n",
    "    substitutes = substitutes[0:12, 0:4] # maximum BPE candidates\n",
    "\n",
    "    # find all possible candidates \n",
    "\n",
    "    all_substitutes = []\n",
    "    for i in range(substitutes.size(0)):\n",
    "        if len(all_substitutes) == 0:\n",
    "            lev_i = substitutes[i]\n",
    "            all_substitutes = [[int(c)] for c in lev_i]\n",
    "        else:\n",
    "            lev_i = []\n",
    "            for all_sub in all_substitutes:\n",
    "                for j in substitutes[i]:\n",
    "                    lev_i.append(all_sub + [int(j)])\n",
    "            all_substitutes = lev_i\n",
    "\n",
    "    # all substitutes  list of list of token-id (all candidates)\n",
    "    c_loss = nn.CrossEntropyLoss(reduction='none')\n",
    "    word_list = []\n",
    "    \n",
    "    # all_substitutes = all_substitutes[:24]\n",
    "    all_substitutes = torch.tensor(all_substitutes) # [ N, L ]\n",
    "    all_substitutes = all_substitutes[:24].to('cuda')\n",
    "    \n",
    "    # print(substitutes.size(), all_substitutes.size())\n",
    "    N, L = all_substitutes.size()\n",
    "    word_predictions = mlm_model(all_substitutes)[0] # N L vocab-size\n",
    "    ppl = c_loss(word_predictions.view(N*L, -1), all_substitutes.view(-1)) # [ N*L ] \n",
    "    ppl = torch.exp(torch.mean(ppl.view(N, L), dim=-1)) # N  \n",
    "    _, word_list = torch.sort(ppl)\n",
    "    word_list = [all_substitutes[i] for i in word_list]\n",
    "    final_words = []\n",
    "    for word in word_list:\n",
    "        tokens = [tokenizer._convert_id_to_token(int(i)) for i in word]\n",
    "        text = tokenizer.convert_tokens_to_string(tokens)\n",
    "        final_words.append(text)\n",
    "    return final_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feature(object):\n",
    "    def __init__(self, seq_a, label):\n",
    "        self.label = label\n",
    "        self.seq = seq_a\n",
    "        self.final_adverse = seq_a\n",
    "        self.query = 0\n",
    "        self.change = 0\n",
    "        self.success = 0\n",
    "        self.sim = 0.0\n",
    "        self.changes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_words = ['a', 'about', 'above', 'across', 'after', 'afterwards', 'again', 'against', 'ain', 'all', 'almost',\n",
    "                'alone', 'along', 'already', 'also', 'although', 'am', 'among', 'amongst', 'an', 'and', 'another',\n",
    "                'any', 'anyhow', 'anyone', 'anything', 'anyway', 'anywhere', 'are', 'aren', \"aren't\", 'around', 'as',\n",
    "                'at', 'back', 'been', 'before', 'beforehand', 'behind', 'being', 'below', 'beside', 'besides',\n",
    "                'between', 'beyond', 'both', 'but', 'by', 'can', 'cannot', 'could', 'couldn', \"couldn't\", 'd', 'didn',\n",
    "                \"didn't\", 'doesn', \"doesn't\", 'don', \"don't\", 'down', 'due', 'during', 'either', 'else', 'elsewhere',\n",
    "                'empty', 'enough', 'even', 'ever', 'everyone', 'everything', 'everywhere', 'except', 'first', 'for',\n",
    "                'former', 'formerly', 'from', 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'he', 'hence',\n",
    "                'her', 'here', 'hereafter', 'hereby', 'herein', 'hereupon', 'hers', 'herself', 'him', 'himself', 'his',\n",
    "                'how', 'however', 'hundred', 'i', 'if', 'in', 'indeed', 'into', 'is', 'isn', \"isn't\", 'it', \"it's\",\n",
    "                'its', 'itself', 'just', 'latter', 'latterly', 'least', 'll', 'may', 'me', 'meanwhile', 'mightn',\n",
    "                \"mightn't\", 'mine', 'more', 'moreover', 'most', 'mostly', 'must', 'mustn', \"mustn't\", 'my', 'myself',\n",
    "                'namely', 'needn', \"needn't\", 'neither', 'never', 'nevertheless', 'next', 'no', 'nobody', 'none',\n",
    "                'noone', 'nor', 'not', 'nothing', 'now', 'nowhere', 'o', 'of', 'off', 'on', 'once', 'one', 'only',\n",
    "                'onto', 'or', 'other', 'others', 'otherwise', 'our', 'ours', 'ourselves', 'out', 'over', 'per',\n",
    "                'please', 's', 'same', 'shan', \"shan't\", 'she', \"she's\", \"should've\", 'shouldn', \"shouldn't\", 'somehow',\n",
    "                'something', 'sometime', 'somewhere', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs',\n",
    "                'them', 'themselves', 'then', 'thence', 'there', 'thereafter', 'thereby', 'therefore', 'therein',\n",
    "                'thereupon', 'these', 'they', 'this', 'those', 'through', 'throughout', 'thru', 'thus', 'to', 'too',\n",
    "                'toward', 'towards', 'under', 'unless', 'until', 'up', 'upon', 'used', 've', 'was', 'wasn', \"wasn't\",\n",
    "                'we', 'were', 'weren', \"weren't\", 'what', 'whatever', 'when', 'whence', 'whenever', 'where',\n",
    "                'whereafter', 'whereas', 'whereby', 'wherein', 'whereupon', 'wherever', 'whether', 'which', 'while',\n",
    "                'whither', 'who', 'whoever', 'whole', 'whom', 'whose', 'why', 'with', 'within', 'without', 'won',\n",
    "                \"won't\", 'would', 'wouldn', \"wouldn't\", 'y', 'yet', 'you', \"you'd\", \"you'll\", \"you're\", \"you've\",\n",
    "                'your', 'yours', 'yourself', 'yourselves']\n",
    "filter_words = set(filter_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _tokenize(seq, tokenizer):\n",
    "    seq = seq.replace('\\n', '').lower()\n",
    "    words = seq.split(' ')\n",
    "    \n",
    "    '''\n",
    "    Needs to create phrase to words mapping\n",
    "    '''\n",
    "\n",
    "    sub_words = []\n",
    "    keys = []\n",
    "    index = 0\n",
    "    for word in words:\n",
    "        sub = tokenizer.tokenize(word)\n",
    "        sub_words += sub\n",
    "        keys.append([index, index + len(sub)])\n",
    "        index += len(sub)\n",
    "\n",
    "    return phrases, sub_words, keys #[word_start, word_end] (subword-index) #[phrase_start, phrase_end] (word index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_unk_masked(units):\n",
    "    len_text = len(units)\n",
    "    masked_units = []\n",
    "    for i in range(len_text - 1):\n",
    "        masked_units.append(units[0:i] + ['[UNK]'] + units[i + 1:])\n",
    "    \n",
    "    # list of masked basic units\n",
    "    return masked_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_phrase_masked(sub_words, phrase2word, word2sub):\n",
    "    masked_subwords = []\n",
    "    for p_start, p_end in phrase2word:\n",
    "        sub_s = word2sub[p_start][0] # inclusive interval start\n",
    "        sub_e = words[p_end - 1][1]  # exclusive interval end\n",
    "        masked_subwords.append(units[0:sub_s] + ['[MASK]'] + units[sub_e:])\n",
    "        \n",
    "    return masked_subwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attack(feature, tgt_model, mlm_model, tokenizer, k, batch_size, max_length=512, cos_mat=None, w2i={}, i2w={}, use_bpe=1, threshold_pred_score=0.3):\n",
    "    # MLM-process\n",
    "    #words, sub_words, keys = _tokenize(feature.seq, tokenizer) #key is the whole word index intervals in sub-words\n",
    "    \n",
    "    phrases, sub_words, keys = _tokenize(feature.seq, tokenizer)\n",
    "    phrase_word_keys, word_subword_keys = keys\n",
    "    \n",
    "    # original label & original probs\n",
    "    inputs = tokenizer.encode_plus(feature.seq, None, add_special_tokens=True, max_length=max_length, )\n",
    "    input_ids, token_type_ids = torch.tensor(inputs[\"input_ids\"]), torch.tensor(inputs[\"token_type_ids\"])\n",
    "    attention_mask = torch.tensor([1] * len(input_ids))\n",
    "    seq_len = input_ids.size(0)\n",
    "    orig_probs = tgt_model(input_ids.unsqueeze(0).to('cuda'),\n",
    "                           attention_mask.unsqueeze(0).to('cuda'),\n",
    "                           token_type_ids.unsqueeze(0).to('cuda')\n",
    "                           )[0].squeeze()\n",
    "    orig_probs = torch.softmax(orig_probs, -1)\n",
    "    orig_label = torch.argmax(orig_probs)\n",
    "    current_prob = orig_probs.max()\n",
    "\n",
    "    if orig_label != feature.label: # if originally wrong classification, return\n",
    "        feature.success = 3\n",
    "        return feature\n",
    "\n",
    "    # starts adversarial computation\n",
    "    sub_words = ['[CLS]'] + sub_words[:max_length - 2] + ['[SEP]']\n",
    "    \n",
    "    '''\n",
    "    get sub_word inputs (#phrases x new_subword_len) where each row got a phrase masked out\n",
    "    '''\n",
    "    subwords_masked_pos_list = _get_phrase_masked(sub_words, phrase_word_keys, word_subword_keys)\n",
    "    input_ids_ = torch.tensor([tokenizer.convert_tokens_to_ids(subwords_masked_pos_list)]) #get indices of sub_words\n",
    "    \n",
    "    '''\n",
    "    additional dimention --> need to test out model shape\n",
    "    '''\n",
    "    word_predictions = mlm_model(input_ids_.to('cuda'))[0].squeeze()  # phrase-len * seq-len(sub) * vocab\n",
    "    word_pred_scores_all, word_predictions = torch.topk(word_predictions, k, -1)  # seq-len k\n",
    "    \n",
    "    # take the top-k predictions (L * K) without special tokens [CLS] and [SEP] \n",
    "    word_predictions = word_predictions[1:len(sub_words) + 1, :]\n",
    "    word_pred_scores_all = word_pred_scores_all[1:len(sub_words) + 1, :]\n",
    "\n",
    "    important_scores = get_important_scores(words, tgt_model, current_prob, orig_label, orig_probs,\n",
    "                                            tokenizer, batch_size, max_length)\n",
    "    \n",
    "    feature.query += int(len(words)) # count number of queries used\n",
    "    \n",
    "    # sort (index, importance score) list in decreasing order - lambda x: x[1] to get importance score\n",
    "    list_of_index = sorted(enumerate(important_scores), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    final_words = copy.deepcopy(words)\n",
    "\n",
    "    for top_index in list_of_index:\n",
    "        if feature.change > int(0.4 * (len(words))):\n",
    "            feature.success = 1  # exceed maximum length of changed words\n",
    "            return feature\n",
    "\n",
    "        tgt_index = top_index[0]\n",
    "        \n",
    "        # original target word\n",
    "        tgt_word = words[tgt_index]\n",
    "        if tgt_word in filter_words: # if target word is in stop words, skip\n",
    "            continue\n",
    "        if keys[tgt_index][0] > max_length - 2: #not exceed max length\n",
    "            continue\n",
    "\n",
    "\n",
    "        # subwords that constitute a word (l * K), l is the length of the subwords\n",
    "        substitutes = word_predictions[keys[tgt_index][0]:keys[tgt_index][1]]  # L, k\n",
    "        word_pred_scores = word_pred_scores_all[keys[tgt_index][0]:keys[tgt_index][1]]\n",
    "\n",
    "        substitutes = get_substitues(substitutes, tokenizer, mlm_model, use_bpe, word_pred_scores, threshold_pred_score)\n",
    "\n",
    "\n",
    "        most_gap = 0.0\n",
    "        candidate = None\n",
    "\n",
    "        for substitute_ in substitutes:\n",
    "            substitute = substitute_\n",
    "\n",
    "            if substitute == tgt_word:\n",
    "                continue  # filter out original word\n",
    "            if '##' in substitute:\n",
    "                continue  # filter out sub-word\n",
    "\n",
    "            if substitute in filter_words: # nltk collected filter words\n",
    "                continue\n",
    "                \n",
    "            # w2i: counter-fitted-vectors (vocab: word to i)\n",
    "            # cos_mat: cos_sim_counter_fitting (similarity matrix)\n",
    "            if substitute in w2i and tgt_word in w2i:\n",
    "                if cos_mat[w2i[substitute]][w2i[tgt_word]] < 0.4: #if 2 words are antonym, skip\n",
    "                    continue\n",
    "            \n",
    "            temp_replace = final_words\n",
    "            temp_replace[top_index[0]] = substitute\n",
    "            temp_text = tokenizer.convert_tokens_to_string(temp_replace)\n",
    "            inputs = tokenizer.encode_plus(temp_text, None, add_special_tokens=True, max_length=max_length, )\n",
    "            input_ids = torch.tensor(inputs[\"input_ids\"]).unsqueeze(0).to('cuda')\n",
    "            seq_len = input_ids.size(1)\n",
    "            temp_prob = tgt_model(input_ids)[0].squeeze()\n",
    "            feature.query += 1\n",
    "            temp_prob = torch.softmax(temp_prob, -1)\n",
    "            temp_label = torch.argmax(temp_prob)\n",
    "\n",
    "            if temp_label != orig_label:\n",
    "                feature.change += 1\n",
    "                final_words[top_index[0]] = substitute\n",
    "                feature.changes.append([keys[top_index[0]][0], substitute, tgt_word])\n",
    "                feature.final_adverse = temp_text\n",
    "                feature.success = 4\n",
    "                return feature\n",
    "            else:\n",
    "\n",
    "                label_prob = temp_prob[orig_label]\n",
    "                gap = current_prob - label_prob\n",
    "                if gap > most_gap:\n",
    "                    most_gap = gap\n",
    "                    candidate = substitute\n",
    "\n",
    "        if most_gap > 0:\n",
    "            feature.change += 1\n",
    "            feature.changes.append([keys[top_index[0]][0], candidate, tgt_word])\n",
    "            current_prob = current_prob - most_gap\n",
    "            final_words[top_index[0]] = candidate\n",
    "\n",
    "    feature.final_adverse = (tokenizer.convert_tokens_to_string(final_words))\n",
    "    feature.success = 2\n",
    "    return feature\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (bert-attack)",
   "language": "python",
   "name": "bert-attack"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

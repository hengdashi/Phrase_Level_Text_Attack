{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "import torch  \n",
    "import datasets\n",
    "from datasets import concatenate_datasets\n",
    "from tqdm import tqdm\n",
    "from transformers import (\n",
    "  AutoTokenizer,\n",
    "  BertForSequenceClassification,\n",
    "  AutoModelForMaskedLM,\n",
    "  pipeline\n",
    ")\n",
    "\n",
    "from common.data_utils import get_dataset\n",
    "from model.tokenizer import PhraseTokenizer\n",
    "from model.attacker import Attacker\n",
    "from model.importance import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForMaskedLM, BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_name = \"bert-large-uncased-whole-word-masking\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "mlm_model = BertForMaskedLM.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_seq = \"What a pity! Frozen 2 is bad compared to its predecessor, which is possibly due to its chaotic production process.\"\n",
    "entry = {'text': tgt_seq}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tagger', 'parser', 'ner', 'merge_noun_chunks', 'merge_entities']\n"
     ]
    }
   ],
   "source": [
    "phrase_tok = PhraseTokenizer()\n",
    "phrase_token_output = phrase_tok.tokenize(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'what a pity! frozen 2 is bad compared to its predecessor, which is possibly due to its chaotic production process.',\n",
       " 'words': ['what',\n",
       "  'a',\n",
       "  'pity',\n",
       "  '!',\n",
       "  'frozen',\n",
       "  '2',\n",
       "  'is',\n",
       "  'bad',\n",
       "  'compared',\n",
       "  'to',\n",
       "  'its',\n",
       "  'predecessor',\n",
       "  ',',\n",
       "  'which',\n",
       "  'is',\n",
       "  'possibly',\n",
       "  'due',\n",
       "  'to',\n",
       "  'its',\n",
       "  'chaotic',\n",
       "  'production',\n",
       "  'process',\n",
       "  '.'],\n",
       " 'word_offsets': [(0, 4),\n",
       "  (5, 6),\n",
       "  (7, 11),\n",
       "  (11, 12),\n",
       "  (13, 19),\n",
       "  (20, 21),\n",
       "  (22, 24),\n",
       "  (25, 28),\n",
       "  (29, 37),\n",
       "  (38, 40),\n",
       "  (41, 44),\n",
       "  (45, 56),\n",
       "  (56, 57),\n",
       "  (58, 63),\n",
       "  (64, 66),\n",
       "  (67, 75),\n",
       "  (76, 79),\n",
       "  (80, 82),\n",
       "  (83, 86),\n",
       "  (87, 94),\n",
       "  (95, 105),\n",
       "  (106, 113),\n",
       "  (113, 114)],\n",
       " 'phrases': ['what a pity',\n",
       "  '!',\n",
       "  'frozen 2',\n",
       "  'is',\n",
       "  'bad',\n",
       "  'compared',\n",
       "  'to',\n",
       "  'its predecessor',\n",
       "  ',',\n",
       "  'which',\n",
       "  'is',\n",
       "  'possibly',\n",
       "  'due',\n",
       "  'to',\n",
       "  'its chaotic production process',\n",
       "  '.'],\n",
       " 'phrase_offsets': [(0, 11),\n",
       "  (11, 12),\n",
       "  (13, 21),\n",
       "  (22, 24),\n",
       "  (25, 28),\n",
       "  (29, 37),\n",
       "  (38, 40),\n",
       "  (41, 56),\n",
       "  (56, 57),\n",
       "  (58, 63),\n",
       "  (64, 66),\n",
       "  (67, 75),\n",
       "  (76, 79),\n",
       "  (80, 82),\n",
       "  (83, 113),\n",
       "  (113, 114)]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrase_token_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_i = 0\n",
    "p_s = 0\n",
    "p_e = phrase_token_output['phrase_offsets'][p_i][1]\n",
    "p_len = 0\n",
    "phrase2word = []\n",
    "new_p = True\n",
    "word_count = 0\n",
    "for w_s, w_e in phrase_token_output['word_offsets']:\n",
    "    \n",
    "    if new_p:\n",
    "        p_s = word_count\n",
    "        new_p = False\n",
    "    \n",
    "    if w_e == p_e:\n",
    "        phrase2word.append([p_s, word_count+1])\n",
    "        new_p = True\n",
    "        p_i = min(p_i + 1, len(phrase_token_output['phrase_offsets']) - 1)\n",
    "        p_e = phrase_token_output['phrase_offsets'][p_i][1]\n",
    "    \n",
    "    word_count += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 3],\n",
       " [3, 4],\n",
       " [4, 6],\n",
       " [6, 7],\n",
       " [7, 8],\n",
       " [8, 9],\n",
       " [9, 10],\n",
       " [10, 12],\n",
       " [12, 13],\n",
       " [13, 14],\n",
       " [14, 15],\n",
       " [15, 16],\n",
       " [16, 17],\n",
       " [17, 18],\n",
       " [18, 22],\n",
       " [22, 23]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrase2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_masked_list = []\n",
    "word2char = phrase_token_output['word_offsets']\n",
    "\n",
    "mask_index_list = []\n",
    "mask_count = 0\n",
    "for p_s, p_e in phrase2word:\n",
    "    if p_e - p_s >= 2:\n",
    "        c_s = word2char[ p_s ][0]\n",
    "        c_e = word2char[ p_e - 1][1]\n",
    "        \n",
    "        mask_len = p_e - p_s\n",
    "        for l in range(1, mask_len+1):\n",
    "            phrase_masked_list.append(tgt_seq[0:c_s] + ' [MASK]' * l + ' ' + tgt_seq[c_e:])\n",
    "            mask_index_list.append([mask_count, mask_count + l])\n",
    "            mask_count += l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' [MASK] ! Frozen 2 is bad compared to its predecessor, which is possibly due to its chaotic production process.',\n",
       " ' [MASK] [MASK] ! Frozen 2 is bad compared to its predecessor, which is possibly due to its chaotic production process.',\n",
       " ' [MASK] [MASK] [MASK] ! Frozen 2 is bad compared to its predecessor, which is possibly due to its chaotic production process.',\n",
       " 'What a pity!  [MASK]  is bad compared to its predecessor, which is possibly due to its chaotic production process.',\n",
       " 'What a pity!  [MASK] [MASK]  is bad compared to its predecessor, which is possibly due to its chaotic production process.',\n",
       " 'What a pity! Frozen 2 is bad compared to  [MASK] , which is possibly due to its chaotic production process.',\n",
       " 'What a pity! Frozen 2 is bad compared to  [MASK] [MASK] , which is possibly due to its chaotic production process.',\n",
       " 'What a pity! Frozen 2 is bad compared to its predecessor, which is possibly due to  [MASK] .',\n",
       " 'What a pity! Frozen 2 is bad compared to its predecessor, which is possibly due to  [MASK] [MASK] .',\n",
       " 'What a pity! Frozen 2 is bad compared to its predecessor, which is possibly due to  [MASK] [MASK] [MASK] .',\n",
       " 'What a pity! Frozen 2 is bad compared to its predecessor, which is possibly due to  [MASK] [MASK] [MASK] [MASK] .']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrase_masked_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' [MASK] ! Frozen 2 is bad compared to its predecessor, which is possibly due to its chaotic production process.',\n",
       " ' [MASK] [MASK] ! Frozen 2 is bad compared to its predecessor, which is possibly due to its chaotic production process.',\n",
       " ' [MASK] [MASK] [MASK] ! Frozen 2 is bad compared to its predecessor, which is possibly due to its chaotic production process.',\n",
       " 'What a pity!  [MASK]  is bad compared to its predecessor, which is possibly due to its chaotic production process.',\n",
       " 'What a pity!  [MASK] [MASK]  is bad compared to its predecessor, which is possibly due to its chaotic production process.',\n",
       " 'What a pity! Frozen 2 is bad compared to  [MASK] , which is possibly due to its chaotic production process.',\n",
       " 'What a pity! Frozen 2 is bad compared to  [MASK] [MASK] , which is possibly due to its chaotic production process.',\n",
       " 'What a pity! Frozen 2 is bad compared to its predecessor, which is possibly due to  [MASK] .',\n",
       " 'What a pity! Frozen 2 is bad compared to its predecessor, which is possibly due to  [MASK] [MASK] .',\n",
       " 'What a pity! Frozen 2 is bad compared to its predecessor, which is possibly due to  [MASK] [MASK] [MASK] .',\n",
       " 'What a pity! Frozen 2 is bad compared to its predecessor, which is possibly due to  [MASK] [MASK] [MASK] [MASK] .']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrase_masked_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11, 25])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encodings = tokenizer(phrase_masked_list, truncation=True, padding=True, return_token_type_ids=False, return_tensors='pt')\n",
    "encodings['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = encodings['input_ids'].to(device)\n",
    "mask_token_index = torch.where(inputs == tokenizer.mask_token_id)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  1,  2,  1,  2,  3,  5,  5,  6, 11, 11, 12, 19, 19, 20, 19, 20, 21,\n",
       "        19, 20, 21, 22], device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_token_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11, 25, 30522])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_logits = mlm_model(inputs, attention_mask=encodings['attention_mask'].to(device)).logits\n",
    "token_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_token_logits = torch.empty(len(mask_token_index), token_logits.shape[2])\n",
    "\n",
    "for i,ind in enumerate(mask_index_list):\n",
    "    li_s = mask_index_list[i][0]\n",
    "    li_e = mask_index_list[i][1]\n",
    "    ind_s = mask_token_index[li_s]\n",
    "    ind_e = mask_token_index[li_e - 1] + 1\n",
    "    #print(li_s, li_e, ind_s, ind_e)\n",
    "        \n",
    "    mask_token_logits[li_s:li_e] = token_logits[i, ind_s:ind_e, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([22, 8])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_8_tokens = torch.topk(mask_token_logits, 8, dim=1).indices\n",
    "top_8_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_substitutes(substitutes, tokenizer, mlm_model):\n",
    "    # all substitutes  list of list of token-id (all candidates)\n",
    "    c_loss = nn.CrossEntropyLoss(reduction='none')\n",
    "    word_list = []\n",
    "\n",
    "    # find all possible candidates \n",
    "    all_substitutes = []\n",
    "    for i in range(substitutes.size(0)):\n",
    "        if len(all_substitutes) == 0:\n",
    "            lev_i = substitutes[i]\n",
    "            all_substitutes = [[int(c)] for c in lev_i]\n",
    "        else:\n",
    "            lev_i = []\n",
    "            for all_sub in all_substitutes:\n",
    "                for j in substitutes[i]:\n",
    "                    lev_i.append(all_sub + [int(j)])\n",
    "            all_substitutes = lev_i\n",
    "\n",
    "    # all_substitutes = all_substitutes[:24]\n",
    "    all_substitutes = torch.tensor(all_substitutes) # [ N, L ]\n",
    "    all_substitutes = all_substitutes[:24].to(device)\n",
    "    \n",
    "    print(all_substitutes.shape) # (K ^ t, K)\n",
    "\n",
    "    N, L = all_substitutes.size()\n",
    "    word_predictions = mlm_model(all_substitutes)[0] # N L vocab-size\n",
    "    ppl = c_loss(word_predictions.view(N*L, -1), all_substitutes.view(-1)) # [ N*L ] \n",
    "    ppl = torch.exp(torch.mean(ppl.view(N, L), dim=-1)) # N  \n",
    "    \n",
    "    _, word_list = torch.sort(ppl)\n",
    "    word_list = [all_substitutes[i] for i in word_list]\n",
    "    final_words = []\n",
    "    for word in word_list[:24]:\n",
    "        tokens = [tokenizer._convert_id_to_token(int(i)) for i in word]\n",
    "        text = tokenizer.convert_tokens_to_string(tokens)\n",
    "        final_words.append(text)\n",
    "        \n",
    "    del all_substitutes\n",
    "    return final_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1])\n",
      "['go', 'ah', 'yo', 'yahoo', 'freeze', 'sorry', 'oh', 'sh']\n",
      " [MASK] ! Frozen 2 is bad compared to its predecessor, which is possibly due to its chaotic production process.\n",
      " go ! Frozen 2 is bad compared to its predecessor, which is possibly due to its chaotic production process.\n",
      " ah ! Frozen 2 is bad compared to its predecessor, which is possibly due to its chaotic production process.\n",
      " oh ! Frozen 2 is bad compared to its predecessor, which is possibly due to its chaotic production process.\n",
      " yo ! Frozen 2 is bad compared to its predecessor, which is possibly due to its chaotic production process.\n",
      " sh ! Frozen 2 is bad compared to its predecessor, which is possibly due to its chaotic production process.\n",
      "\n",
      "torch.Size([24, 2])\n",
      "['hey', 'never', 'yu', 'the', 'get', 'ice', 'o', 'ala']\n",
      "['up', 'go', 'attack', '##cha', 'it', 'you', 'out', '##bba']\n",
      " [MASK] [MASK] ! Frozen 2 is bad compared to its predecessor, which is possibly due to its chaotic production process.\n",
      " yu it ! Frozen 2 is bad compared to its predecessor, which is possibly due to its chaotic production process.\n",
      " yu out ! Frozen 2 is bad compared to its predecessor, which is possibly due to its chaotic production process.\n",
      " never up ! Frozen 2 is bad compared to its predecessor, which is possibly due to its chaotic production process.\n",
      " yubba ! Frozen 2 is bad compared to its predecessor, which is possibly due to its chaotic production process.\n",
      " yu go ! Frozen 2 is bad compared to its predecessor, which is possibly due to its chaotic production process.\n",
      "\n",
      "torch.Size([24, 3])\n",
      "['the', 'sh', 'never', 'ya', 'yu', 'hey', 'aaa', 'o']\n",
      "['!', '-', '##hh', '##cha', ',', '##tar', \"'\", '##de']\n",
      "['##o', '##a', 'yo', 'you', '##m', '##h', '##g', '##s']\n",
      " [MASK] [MASK] [MASK] ! Frozen 2 is bad compared to its predecessor, which is possibly due to its chaotic production process.\n",
      " the !m ! Frozen 2 is bad compared to its predecessor, which is possibly due to its chaotic production process.\n",
      " thehha ! Frozen 2 is bad compared to its predecessor, which is possibly due to its chaotic production process.\n",
      " the -s ! Frozen 2 is bad compared to its predecessor, which is possibly due to its chaotic production process.\n",
      " thehhs ! Frozen 2 is bad compared to its predecessor, which is possibly due to its chaotic production process.\n",
      " the -a ! Frozen 2 is bad compared to its predecessor, which is possibly due to its chaotic production process.\n",
      "\n",
      "torch.Size([8, 1])\n",
      "['it', 'this', '!', ',', 'which', 'that', 'production', 'sequel']\n",
      "What a pity!  [MASK]  is bad compared to its predecessor, which is possibly due to its chaotic production process.\n",
      "What a pity!  ,  is bad compared to its predecessor, which is possibly due to its chaotic production process.\n",
      "What a pity!  it  is bad compared to its predecessor, which is possibly due to its chaotic production process.\n",
      "What a pity!  that  is bad compared to its predecessor, which is possibly due to its chaotic production process.\n",
      "What a pity!  this  is bad compared to its predecessor, which is possibly due to its chaotic production process.\n",
      "What a pity!  which  is bad compared to its predecessor, which is possibly due to its chaotic production process.\n",
      "\n",
      "torch.Size([24, 2])\n",
      "['the', 'this', 'its', 'that', 'second', ',', 'my', 'our']\n",
      "['film', 'sequel', 'movie', 'album', 'game', 'series', 'one', '2']\n",
      "What a pity!  [MASK] [MASK]  is bad compared to its predecessor, which is possibly due to its chaotic production process.\n",
      "What a pity!  the one  is bad compared to its predecessor, which is possibly due to its chaotic production process.\n",
      "What a pity!  the film  is bad compared to its predecessor, which is possibly due to its chaotic production process.\n",
      "What a pity!  the movie  is bad compared to its predecessor, which is possibly due to its chaotic production process.\n",
      "What a pity!  this one  is bad compared to its predecessor, which is possibly due to its chaotic production process.\n",
      "What a pity!  the series  is bad compared to its predecessor, which is possibly due to its chaotic production process.\n",
      "\n",
      "torch.Size([8, 1])\n",
      "['frozen', 'it', 'predecessor', '3', 'original', 'first', 'its', '1']\n",
      "What a pity! Frozen 2 is bad compared to  [MASK] , which is possibly due to its chaotic production process.\n",
      "What a pity! Frozen 2 is bad compared to  it , which is possibly due to its chaotic production process.\n",
      "What a pity! Frozen 2 is bad compared to  its , which is possibly due to its chaotic production process.\n",
      "What a pity! Frozen 2 is bad compared to  3 , which is possibly due to its chaotic production process.\n",
      "What a pity! Frozen 2 is bad compared to  1 , which is possibly due to its chaotic production process.\n",
      "What a pity! Frozen 2 is bad compared to  first , which is possibly due to its chaotic production process.\n",
      "\n",
      "torch.Size([24, 2])\n",
      "['its', 'frozen', 'the', 'previous', 'ice', 'it', 'their', 'original']\n",
      "['predecessor', 'original', '1', 'predecessors', 'first', 'one', 'film', '2']\n",
      "What a pity! Frozen 2 is bad compared to  [MASK] [MASK] , which is possibly due to its chaotic production process.\n",
      "What a pity! Frozen 2 is bad compared to  the one , which is possibly due to its chaotic production process.\n",
      "What a pity! Frozen 2 is bad compared to  the film , which is possibly due to its chaotic production process.\n",
      "What a pity! Frozen 2 is bad compared to  the first , which is possibly due to its chaotic production process.\n",
      "What a pity! Frozen 2 is bad compared to  its film , which is possibly due to its chaotic production process.\n",
      "What a pity! Frozen 2 is bad compared to  the predecessor , which is possibly due to its chaotic production process.\n",
      "\n",
      "torch.Size([8, 1])\n",
      "['marketing', 'censorship', 'age', 'nostalgia', 'this', 'pacing', 'gameplay', 'hunger']\n",
      "What a pity! Frozen 2 is bad compared to its predecessor, which is possibly due to  [MASK] .\n",
      "What a pity! Frozen 2 is bad compared to its predecessor, which is possibly due to  this .\n",
      "What a pity! Frozen 2 is bad compared to its predecessor, which is possibly due to  age .\n",
      "What a pity! Frozen 2 is bad compared to its predecessor, which is possibly due to  hunger .\n",
      "What a pity! Frozen 2 is bad compared to its predecessor, which is possibly due to  marketing .\n",
      "What a pity! Frozen 2 is bad compared to its predecessor, which is possibly due to  pacing .\n",
      "\n",
      "torch.Size([24, 2])\n",
      "['its', 'the', 'poor', 'some', 'technical', 'a', 'budget', 'several']\n",
      "['issues', 'gameplay', 'problems', 'differences', 'content', 'factors', 'difficulties', 'bugs']\n",
      "What a pity! Frozen 2 is bad compared to its predecessor, which is possibly due to  [MASK] [MASK] .\n",
      "What a pity! Frozen 2 is bad compared to its predecessor, which is possibly due to  the difficulties .\n",
      "What a pity! Frozen 2 is bad compared to its predecessor, which is possibly due to  the problems .\n",
      "What a pity! Frozen 2 is bad compared to its predecessor, which is possibly due to  the bugs .\n",
      "What a pity! Frozen 2 is bad compared to its predecessor, which is possibly due to  its content .\n",
      "What a pity! Frozen 2 is bad compared to its predecessor, which is possibly due to  the issues .\n",
      "\n",
      "torch.Size([24, 3])\n",
      "['its', 'the', 'a', 'poor', 'lack', 'an', 'some', 'increased']\n",
      "['of', 'poor', 'technical', 'and', 'gameplay', 'game', 'time', 'over']\n",
      "['engine', 'gameplay', 'issues', 'system', '##s', 'content', 'problems', 'difference']\n",
      "What a pity! Frozen 2 is bad compared to its predecessor, which is possibly due to  [MASK] [MASK] [MASK] .\n",
      "What a pity! Frozen 2 is bad compared to its predecessor, which is possibly due to  its technical issues .\n",
      "What a pity! Frozen 2 is bad compared to its predecessor, which is possibly due to  its of engine .\n",
      "What a pity! Frozen 2 is bad compared to its predecessor, which is possibly due to  its of system .\n",
      "What a pity! Frozen 2 is bad compared to its predecessor, which is possibly due to  its of gameplay .\n",
      "What a pity! Frozen 2 is bad compared to its predecessor, which is possibly due to  its ofs .\n",
      "\n",
      "torch.Size([24, 4])\n",
      "['the', 'its', 'a', 'lack', 'an', 'inc', 'over', 'some']\n",
      "['lack', 'of', 'g', 'over', 'poor', 'and', \"'\", '-']\n",
      "['of', '##lit', 'and', 'in', 'game', 's', '##tri', '##per']\n",
      "['##s', 'gameplay', 'content', 'issues', 'engine', 'system', '##ing', 'problems']\n",
      "What a pity! Frozen 2 is bad compared to its predecessor, which is possibly due to  [MASK] [MASK] [MASK] [MASK] .\n",
      "What a pity! Frozen 2 is bad compared to its predecessor, which is possibly due to  the lack of issues .\n",
      "What a pity! Frozen 2 is bad compared to its predecessor, which is possibly due to  the lack of engine .\n",
      "What a pity! Frozen 2 is bad compared to its predecessor, which is possibly due to  the lack of gameplay .\n",
      "What a pity! Frozen 2 is bad compared to its predecessor, which is possibly due to  the lacklit content .\n",
      "What a pity! Frozen 2 is bad compared to its predecessor, which is possibly due to  the lack of problems .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for (i, (p_s, p_e)) in enumerate(mask_index_list):\n",
    "    cur_phrase = ''\n",
    "    substitutes = top_8_tokens[p_s:p_e]\n",
    "    final_words = get_substitutes(substitutes, tokenizer, mlm_model)\n",
    "    for s in substitutes:\n",
    "        print(tokenizer.convert_ids_to_tokens(s))\n",
    "    \n",
    "    print(phrase_masked_list[i])\n",
    "    for w in final_words[:5]:\n",
    "        print(phrase_masked_list[i].replace((f' {tokenizer.mask_token}' * (p_e - p_s))[1:], w))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importance Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_model = BertForSequenceClassification.from_pretrained('./data/imdb/saved_model/imdb_bert_base_uncased_finetuned_normal').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. retrieve logits and label from the target model\n",
    "inputs = tokenizer(entry['text'], return_tensors=\"pt\", truncation=True, max_length=512, return_token_type_ids=False)\n",
    "orig_logits = target_model(inputs['input_ids'].to(device), inputs['attention_mask'].to(device))[0].squeeze()\n",
    "orig_probs  = torch.softmax(orig_logits, -1)\n",
    "orig_label = torch.argmax(orig_probs)\n",
    "current_prob = orig_probs.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (2) must match the size of tensor b (15) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-a6093bf2fea5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimportance\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_important_scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mget_important_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_probs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/python_projects/NLP_ADV/model/importance.py\u001b[0m in \u001b[0;36mget_important_scores\u001b[0;34m(entry, tokenizer, target_model, orig_label, orig_logits, orig_probs, batch_size, max_length)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (2) must match the size of tensor b (15) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "from model.importance import get_important_scores\n",
    "get_important_scores(entry, tokenizer, target_model, orig_label, orig_logits, orig_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return units masked with UNK at each position in the sequence\n",
    "def _get_unk_masked(units):\n",
    "    len_text = len(units)\n",
    "    masked_units = []\n",
    "    for i in range(len_text - 1):\n",
    "        masked_units.append(units[0:i] + ['[UNK]'] + units[i + 1:])\n",
    "    \n",
    "    # list of masked basic units\n",
    "    return masked_units\n",
    "\n",
    "'''\n",
    "input units should be phrase tokens\n",
    "'''\n",
    "def get_important_scores(units, tgt_model, orig_prob, orig_label, orig_probs, tokenizer, batch_size=8, max_length=512):\n",
    "    masked_units = _get_unk_masked(units)\n",
    "    texts = [' '.join(units) for units in masked_units]  # list of text of masked units\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    print(tokenizer)\n",
    "    encodings = tokenizer(texts, truncation=True, padding='max_length', max_length=max_length, return_token_type_ids=False, return_tensors='pt')\n",
    "    \n",
    "    eval_data = TensorDataset(encodings['input_ids'], encodings['attention_mask'])\n",
    "\n",
    "    # Run prediction for full data\n",
    "    eval_sampler = SequentialSampler(eval_data)\n",
    "    eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=batch_size)\n",
    "    leave_1_probs = []\n",
    "    \n",
    "    tgt_model.eval() #make sure in inference stage\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in eval_dataloader:\n",
    "            input_ids = batch[0].to(device)      # input ids\n",
    "            attention_mask = batch[1].to(device) # attention mask\n",
    "        \n",
    "            leave_1_prob_batch = tgt_model(input_ids, attention_mask=attention_mask)[0]\n",
    "            leave_1_probs.append(leave_1_prob_batch)\n",
    "        \n",
    "    leave_1_probs = torch.cat(leave_1_probs, dim=0)  # words, num-label\n",
    "    leave_1_probs = torch.softmax(leave_1_probs, -1)\n",
    "    leave_1_probs_argmax = torch.argmax(leave_1_probs, dim=-1)\n",
    "    import_scores = (orig_prob\n",
    "                     - leave_1_probs[:, orig_label] # how the probability of original label decreases\n",
    "                     +\n",
    "                     (leave_1_probs_argmax != orig_label).float() # new label not equal to original label\n",
    "                     * (leave_1_probs.max(dim=-1)[0] - torch.index_select(orig_probs, 0, leave_1_probs_argmax))\n",
    "                     ).data.cpu().numpy()           # probability of changed label\n",
    "\n",
    "    return import_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PreTrainedTokenizer(name_or_path='bert-large-uncased-whole-word-masking', vocab_size=30522, model_max_len=512, is_fast=False, padding_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})\n"
     ]
    }
   ],
   "source": [
    "importance = get_important_scores(entry['phrases'], target_model, current_prob, orig_label, orig_probs, tokenizer, batch_size=8, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_indices = torch.argsort(torch.tensor(importance), dim=-1, descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "sorted_units = np.array(units)[sorted_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('what a pity', 0.027897894),\n",
       " ('!', 0.010043323),\n",
       " ('bad', 0.007974029),\n",
       " ('frozen 2', 0.00469023),\n",
       " ('is', 0.0031422377),\n",
       " ('possibly', 0.003043294),\n",
       " ('its chaotic production process', 0.0026093125),\n",
       " ('its predecessor', 0.001532495),\n",
       " ('due', 0.0013412237),\n",
       " ('compared', 0.0013231635),\n",
       " ('to', 0.001247406),\n",
       " ('to', 0.00043827295),\n",
       " ('is', 0.00033521652),\n",
       " (',', -0.0005329251),\n",
       " ('which', -0.0006894469)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(u,i) for (u,i) in zip(sorted_units, importance[sorted_indices])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (bert-attack)",
   "language": "python",
   "name": "bert-attack"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
